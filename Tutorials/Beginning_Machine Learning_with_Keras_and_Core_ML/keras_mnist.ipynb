{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tutorial\n",
    "\n",
    "Apple의 Core ML 및 Vison Framework로 간단하게 Machine Learning을 구현할 수 있다.    \n",
    "Turi Create를 사용해 미리 훈련된 모델 중 하나를 가져와 transfer learning을 할 수도 있다.    \n",
    "하지만, 개별적인 커스터마이징이 필요하다면 TensorFlow, Keras, PyTorch 등의 Framework를 사용해야 한다.  \n",
    "\n",
    "## Why Use Keras?\n",
    "- scikit-learn으로 linear regression나 support vector machine 등의 ML 알고리즘을 쉽게 실행할 수 있다.\n",
    "- PyTorch, TensorFlow 등으로 Deep learning model을 더 세세하게 제어할 수 있다.\n",
    "- 다른 Deep learning framework인 CNTK(Microsoft), Caffe(Berkeley)는 C++ 에 액세스할 수 있는 Python API이다.\n",
    "    \n",
    "Keras는 TensorFlow와 CNTK의 wrapper이면서 Amazon의 MXNet 이 곧 추가될 예정이다.    \n",
    "backend에서 쉽게 training할 수 있고 배포고 쉽다.    \n",
    "TensorFlow를 직접 사용하는 것보다 Keras를 사용하는 다른 이유는 coremltools이 Keras converter를 포함하고 있기 때문이다.    \n",
    "TensorFlow to CoreML converter와 MXNet to CoreML converter가 있지만, TensorFlow converter는 coremltools에 없다.    \n",
    "Keras는 CNTK를 backend로 지원하지만, coremltools는 Keras + TensorFlow에서만 작동한다.    \n",
    "coremltools은 Python 2와 Python 3를 모두 지원하지만, Python 2.7에서 가장 최적화되어 있다.    \n",
    "\n",
    "## Setting Up Docker\n",
    "Docker는 가상 머신과 같이 customized environment을 배포할 수 있는 container platform이다.    \n",
    "배포되어 있는 Docker image로 수 많은 ML 리소스에 액세스할 수 있다.    \n",
    "Docker를 실행한 후, 해당 폴더에서    \n",
    "\n",
    "docker build -t keras-mnist .    \n",
    "docker run --rm -it -p 8888:8888 -v $(pwd)/notebook:/workspace/notebook keras-mnist \n",
    "    \n",
    "Docker 컨테이너의 notebook 폴더를 로컬 notebook 폴더에 매핑하므로 Docker 서버를 로그 아웃 한 후에도 파일에 액세스할 수 있다.     \n",
    "토큰을 포함하는 URL을 출력하는데 해당 URL을 브라우저에 붙여 넣으면 된다(Docker 서버의 notebook을 연다).    \n",
    "\n",
    "### ML in a Nutshell\n",
    "Arthur Samuel은 기계 학습을 \"컴퓨터에 명시 적으로 프로그래밍하지 않고 학습 할 수있는 능력을 부여하는 연구 분야\"라고 정의했다.    \n",
    "충분한 데이터가 있는 경우 모델을 훈련시켜 패턴을 인식한 다음 새로운 데이터에 적용할 수 있다.    \n",
    "모든 training 데이터에 대한 올바른 결과(정답)를 알고 있는 것을 supervised learning이라 한다.    \n",
    "지도 학습에서 모델은 예측을 정답과 비교해 오차를 줄이고 정확도를 높이기 위해 스스로 조절한다.    \n",
    "\n",
    "### Weights & Threshold\n",
    "결정을 위한 각 요인에 다른 가중치를 지정한다. 가 요인의 값에 각 요인의 가중치를 곱한 다음 가중치 합(weighted sum)을 얻기 위해 이를 더한다.    \n",
    "가장 높은 결과를 얻는 결과가 최선의 선택이 된다. 모델을 사용하는 다른 방법은 binary output(Yes/No)를 출력하는 것이다.    \n",
    "임계값을 정하고, 가중치 합이 임계 값 아래로 떨어지는 선택을 목록에서 제거한다.    \n",
    "\n",
    "### Training an ML Model\n",
    "가중치를 구하는 것은 쉬운 일이 아니지만, 많은 데이터에서 ML 모델을 훈련하면서 조절해 나갈 수 있다.    \n",
    "ML 모델을 학습하려면 임의의 가중치로 시작하여 training data에 적용한 다음 출력을 정답과 비교해 오류를 계산한다.    \n",
    "이(오류)는 최소값을 갖는 다차원 함수이고 훈련의 목표는 이 최소값에 매우 가깝게 도달하는 가중치를 구하는 것이다.    \n",
    "overfitting이 일어나지 않도록 염두 해야 한다.\n",
    "\n",
    "### Stochastic Gradient Descent\n",
    "오류 함수의 기울기를 계산한 다음 가중치를 조정해 기울기를 줄인다. 이를 gradient descent라 하며, 적절한 가중치를 찾는데 사용된다.    \n",
    "SGD(Stochastic gradient descent)는 무작위로 선택된 training data의 mini-batch에서 기울기를 추정한다.    \n",
    "\n",
    "### Optimizers\n",
    "현재 가장 많이 사용하는 최적화 함수는 Adam(Adaptive Moment estimation)이다.    \n",
    "이전에 많이 쓰던 RMSprop(Root Mean Square propagation)와 AdaGrad(Adaptive Gradient algorithm)를 결합한 모델이다.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utilities & Dependencies\n",
    "\n",
    "- `print_function` works in Python 2 and Python 3\n",
    "- Keras uses the NumPy mathematics library to manipulate arrays and matrices. Matplotlib is a plotting library for NumPy: you'll use it to inspect a training data item.\n",
    "- Import Keras 2.0.6 and the components needed for the model. [FutureWarning due to NumPy 1.14](https://github.com/h5py/h5py/issues/961)\n",
    "- Import coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version  2.0.6\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "# __future__ 는 Python2 와 Python3 의 호환성 레이어 이다. \n",
    "#Python2 에서는 print 를 쓰지만, Python3 에서는 print()를 사용한다. print_function를 import해 가져오면, Python2 에서 print()를 쓸 수 있다.\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "import coremltools #Core ML 로 모델을 검사, 작성, 테스트 할 수 있는 Python 패키지\n",
    "# coremltools supports Keras version 2.0.6\n",
    "print('keras version ', keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Pre-Process Data\n",
    "\n",
    "### Training and Testing/Validation Sets\n",
    "\n",
    "`mnist.load_data()` downloads from https://s3.amazonaws.com/img-datasets/mnist.npz — this takes a little while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11403264/11490434 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# First, get your data!\n",
    "(x_train, y_train), (x_val, y_val) = mnist.load_data()\n",
    "#데이터를 다운로드 하고, 항목을 셔플한 후, training 데이터와 validation 데이터로 분리한다.\n",
    "#validation 으로 모델이 overfitting 되었는지 여부를 감지하는 데 도움이 된다.\n",
    "#training을 하면서, 수정된 매개 변수를 사용해 validation data의 출력을 계산한다.\n",
    "#그 결과로 손실 및 정확도를 비교해 가장 나은 모델을 저장하고, 많은 반복(epoch)에도 손실 및 정확도가 향상되지 않으면 초기에 중지하는 콜백을 설정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect x and y Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28)\n",
      "60000 training samples\n",
      "x_val shape:  (10000, 28, 28)\n",
      "10000 validation samples\n",
      "First x sample\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape:  (60000,)\n",
      "First 10 y_train elements: [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# Inspect x data\n",
    "print('x_train shape: ', x_train.shape) #28 x 28 픽셀의 training data 60000 개\n",
    "# Displays (60000, 28, 28)\n",
    "print(x_train.shape[0], 'training samples')\n",
    "# Displays 60000 train samples\n",
    "print('x_val shape: ', x_val.shape) #28 x 28 픽셀의 validation data 10000 개\n",
    "# Displays (10000, 28, 28)\n",
    "print(x_val.shape[0], 'validation samples')\n",
    "# Displays 10000 validation samples\n",
    "\n",
    "print('First x sample\\n', x_train[0])\n",
    "# Displays an array of 28 arrays, each containing 28 gray-scale values between 0 and 255\n",
    "# Plot first x sample\n",
    "#각 요소가 28개인 배열 28개로 이루어져 있으며, 각 요소는 0에서 255까지의 gray-scale 값을 가지고 있다.\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()\n",
    "#plt로 배열을 이미지로 출력한다.\n",
    "\n",
    "# Inspect y data\n",
    "print('y_train shape: ', y_train.shape) #y 는 정답의 레이블을 가지고 있는 배열이다.\n",
    "# Displays (60000,)\n",
    "print('First 10 y_train elements:', y_train[:10])\n",
    "# Displays [5 0 4 1 9 2 1 3 1 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input and output dimensions\n",
    "\n",
    "MNIST data items are 28 x 28-pixel images, and you want to classify each as a digit between 0 and 9.\n",
    "\n",
    "`x_train.shape` is an array of 3 elements: number of data samples, number of rows of each data sample, number of columns of each data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = x_train.shape[1], x_train.shape[2] # 각 이미지 배열의 행(28), 각 이미지 배열의 열(28)\n",
    "num_classes = 10 #분류하고자 하는 클래스의 수\n",
    "#MNIST data는 28 x 28 이미지 이며, 각 0 ~ 9 사이의 숫자를 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape x Data & Set Input Shape\n",
    "\n",
    "- Insert the channels, either before or after the image's rows and columns. MNIST data samples are gray-scale, so the number of channels is 1.\n",
    "- Set the input shape of the sample data, with the channels at the correct end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set input_shape for channels_first or channels_last\n",
    "if K.image_data_format() == 'channels_first': #위에서 선언할 때 K는 keras의 backend로 선언했다.\n",
    "    #channels-first format (channels, rows, columns)\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    #reshpe 전 x_train.shape은 (60000, 28, 28) 였다.\n",
    "    x_val = x_val.reshape(x_val.shape[0], 1, img_rows, img_cols)\n",
    "    #reshpe 전 x_val.shape은 (10000, 28, 28) 였다.\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else: #channels-last format(rows, columns, channels)\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    #reshpe 전 x_train.shape은 (60000, 28, 28) 였다.\n",
    "    x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols, 1)\n",
    "    #reshpe 전 x_val.shape은 (10000, 28, 28) 였다.\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "#TensorFlow, CNTK와 같은 Keras 백엔드는 channels-last format(rows, columns, channels) 또는\n",
    "#channels-first format (channels, rows, columns) 로 선언한다.\n",
    "#reshape로 이 형식에 맞춰 채널의 올바른 위치에 삽입해 준다.\n",
    "    \n",
    "#Convolutional neural network 는 이미지의 width, height, depth 정보를 사용한다.\n",
    "#depth는 channel이라고도 하며, 색상 정보를 포함한다. ex. Gray-scale image는 채널이 1개, RGB image는 채널이 3개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Reshaped x Data\n",
    "\n",
    "TensorFlow image data format is channels-last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "x_val shape: (10000, 28, 28, 1)\n",
      "input_shape: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "# x_train shape: (60000, 28, 28, 1)\n",
    "print('x_val shape:', x_val.shape)\n",
    "# x_val shape: (10000, 28, 28, 1)\n",
    "print('input_shape:', input_shape)\n",
    "# input_shape: (28, 28, 1)\n",
    "\n",
    "#제대로 reshape 됐는 지 확인 한다. channels-last format(rows, columns, channels)이 적용되었다.\n",
    "#reshpe 전 x_train.shape은 (60000, 28, 28), x_val.shape은 (10000, 28, 28) 였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data Type And Normalize Values\n",
    "\n",
    "MNIST image data values are of type `uint8`, in the range [0, 255], but Keras needs values of type `float32`, in the range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') \n",
    "x_val = x_val.astype('float32')\n",
    "#float32로 type을 변환한다.\n",
    "\n",
    "x_train /= 255\n",
    "x_val /= 255\n",
    "#[0, 1] 사이의 값으로 맞추기 위해 255로 나눠준다.\n",
    "\n",
    "#모델은 매개변수 타입을 맞춰주기 위해 데이터의 type을 변경해 줘야 한다.\n",
    "#MNIST image data의 type은 uint8 이며, 범위는 [0, 255]가 된다. 그러나 Keras의 type은 float32 이며 범위는 [0, 1]이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Normalized x Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First x sample, normalized\n",
      " [[[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01176471]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.49411765]\n",
      "  [0.53333336]\n",
      "  [0.6862745 ]\n",
      "  [0.10196079]\n",
      "  [0.6509804 ]\n",
      "  [1.        ]\n",
      "  [0.96862745]\n",
      "  [0.49803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.11764706]\n",
      "  [0.14117648]\n",
      "  [0.36862746]\n",
      "  [0.6039216 ]\n",
      "  [0.6666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.88235295]\n",
      "  [0.6745098 ]\n",
      "  [0.99215686]\n",
      "  [0.9490196 ]\n",
      "  [0.7647059 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.19215687]\n",
      "  [0.93333334]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.9843137 ]\n",
      "  [0.3647059 ]\n",
      "  [0.32156864]\n",
      "  [0.32156864]\n",
      "  [0.21960784]\n",
      "  [0.15294118]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.7137255 ]\n",
      "  [0.96862745]\n",
      "  [0.94509804]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.3137255 ]\n",
      "  [0.6117647 ]\n",
      "  [0.41960785]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8039216 ]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.16862746]\n",
      "  [0.6039216 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.05490196]\n",
      "  [0.00392157]\n",
      "  [0.6039216 ]\n",
      "  [0.99215686]\n",
      "  [0.3529412 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.54509807]\n",
      "  [0.99215686]\n",
      "  [0.74509805]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.04313726]\n",
      "  [0.74509805]\n",
      "  [0.99215686]\n",
      "  [0.27450982]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.13725491]\n",
      "  [0.94509804]\n",
      "  [0.88235295]\n",
      "  [0.627451  ]\n",
      "  [0.42352942]\n",
      "  [0.00392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.31764707]\n",
      "  [0.9411765 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.46666667]\n",
      "  [0.09803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.1764706 ]\n",
      "  [0.7294118 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.5882353 ]\n",
      "  [0.10588235]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.0627451 ]\n",
      "  [0.3647059 ]\n",
      "  [0.9882353 ]\n",
      "  [0.99215686]\n",
      "  [0.73333335]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.9764706 ]\n",
      "  [0.99215686]\n",
      "  [0.9764706 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.18039216]\n",
      "  [0.50980395]\n",
      "  [0.7176471 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8117647 ]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.15294118]\n",
      "  [0.5803922 ]\n",
      "  [0.8980392 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.98039216]\n",
      "  [0.7137255 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09411765]\n",
      "  [0.44705883]\n",
      "  [0.8666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7882353 ]\n",
      "  [0.30588236]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09019608]\n",
      "  [0.25882354]\n",
      "  [0.8352941 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.31764707]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.67058825]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7647059 ]\n",
      "  [0.3137255 ]\n",
      "  [0.03529412]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.21568628]\n",
      "  [0.6745098 ]\n",
      "  [0.8862745 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.95686275]\n",
      "  [0.52156866]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.53333336]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.83137256]\n",
      "  [0.5294118 ]\n",
      "  [0.5176471 ]\n",
      "  [0.0627451 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print('First x sample, normalized\\n', x_train[0])\n",
    "# An array of 28 arrays, each containing 28 arrays, each with one value between 0 and 1\n",
    "#각 배열의 요소 type은 float 이며, 0과 1 사이의 값을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat y Data\n",
    "\n",
    "`y_train` is a 1-dimensional array with 60000 elements, but the model needs a 60000 x 10 matrix to represent the 10 categories.\n",
    "\n",
    "**Note:** Run this cell **once only**! Running it again will produce incorrect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape:  (60000,)\n",
      "First 10 y_train elements: [5 0 4 1 9 2 1 3 1 4]\n",
      "New y_train shape:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('y_train shape: ', y_train.shape) #y_train은 정답 레이블 요소가 60000개 있는 1차원 배열이다.\n",
    "# (60000,)\n",
    "print('First 10 y_train elements:', y_train[:10])\n",
    "# [5 0 4 1 9 2 1 3 1 4]\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_val = np_utils.to_categorical(y_val, num_classes)\n",
    "#600000개의 요소가 있는 1차원 배열을 각 10개의 카테고리를 요소로 가지고 있는 배열 60000 개로 reformatting 한다. one-hot encoding\n",
    "print('New y_train shape: ', y_train.shape)\n",
    "# (60000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Reformatted y Data\n",
    "\n",
    "`y_train` is now an array of 10-element arrays, each containing all zeros except at the index that the image matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New y_train shape:  (60000, 10)\n",
      "First 10 y_train elements, reshaped:\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('New y_train shape: ', y_train.shape)\n",
    "# (60000, 10)\n",
    "print('First 10 y_train elements, reshaped:\\n', y_train[:10])\n",
    "# An array of 10 arrays, each with 10 elements, \n",
    "# all zeros except at index 5, 0, 4, 1, 9 etc.\n",
    "#one-hot encoding으로 reformat 되어, 해당 카테고리에 해당하는 요소만 1이고, 나머지는 0이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define  model architecture\n",
    "\n",
    "### [Malireddi's Architecture](https://sriraghu.com/2017/07/06/computer-vision-in-ios-coremlkerasmnist/)\n",
    "\n",
    "Malireddi's Architecture은 모바일 앱에 적합한 작은 모델이다. Chollet’s Architecture보다 convolutional layer(Conv2D)를 하나 더 가지고 있지만, 훨씬 더 빠르게 실행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 128)         8320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 94,602\n",
      "Trainable params: 94,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_m = Sequential() #먼저 빈 Sequential 생성 후, linear stack 레이어를 추가한다.\n",
    "#첫 layer 에는 MNIST 이미지의 input shape에 대한 정보가 있어야 한다(28, 28, 1).\n",
    "#다른 layer는 이전 layer의 output shape에서 input shape를 추론한다. \n",
    "#이 모델에는 Conv2D 레이어 계층이 3 개 있다.\n",
    "model_m.add(Conv2D(32, (5, 5), input_shape=input_shape, activation='relu'))\n",
    "#첫 매개변수 32는 이 레이어에서 탐지해 훈련하려는 filter 또는 feature의 수 이다. 이는 ouput shape의 depth이기도 하다.\n",
    "#두 번째 매개변수 (5, 5)는 커널의 크기이다. convolution window의 width 와 height를 지정하는 튜플이며 가중치 합을 계산한다.\n",
    "#  가중치 합은 커널의 weight와 input unit values의 dot 연산으로 계산한다.\n",
    "#세 번째 매개변수 activation='relu'는 활성 함수이다. Relu는 deep neural networks에서 가장 흔히 사용되는 활성화 함수이다.\n",
    "model_m.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#MaxPooling는 pool_size(2 x 2, 일반적으로 정사각형) 크기의 필터에서 가장 큰 값을 선택해 매개변수의 수를 줄인다. 오버피팅을 방지한다.\n",
    "#이 모델에서는 각 Conv layer 층 다음에 MaxPooling을 한다. 빈번하게 MaxPooling하기 때문에 최종 모델의 크기와 학습 시간이 크게 줄어든다.\n",
    "#Conv2D와 MaxPooling2D의 매개변수는 각 레이어의 ouput shape과 학습 가능한 매개 변수 수를 결정한다.\n",
    "#Output Shape = (input width – kernel width + 1, input height – kernel height + 1, number of filters)\n",
    "model_m.add(Dropout(0.5))\n",
    "#Dropout은 MaxPooling과 쌍을 이루는 경우가 많다. 이는 랜덤으로 input unit의 일부를 0으로 설정해 overfitting을 방지한다.\n",
    "#CNN의 뉴런은 인접한 뉴런에 큰 영향을 받기 때문에 랜덤하게 값을 삭제해 네트워크가 작은 변화에 덜 민감하도록 일반화시킨다.\n",
    "model_m.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_m.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_m.add(Dropout(0.2))\n",
    "model_m.add(Conv2D(128, (1, 1), activation='relu'))\n",
    "model_m.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_m.add(Dropout(0.2))\n",
    "model_m.add(Flatten()) \n",
    "#convolutional layer의 가중치는 fully connected Dense layer로 전달하기 전에 1차원으로 만들어야 한다.\n",
    "#이전 레이어의 ouput shape는 (2, 2, 128) 이므로 Flatten()의 output은 512 개의 요소가 있는 배열ㅇ; 된다.\n",
    "model_m.add(Dense(128, activation='relu'))\n",
    "#convolutional layer의 각 뉴런은 이전 레이어의 몇 개의 뉴런 값만 사용한다. 하지만 fully connected layer로 만들면, 이전 레이어의 모든 값을 사용한다.\n",
    "#Keras에서는 Dense로 FC 레이어를 만든다. output이 128이 된다. FC의 input shape가 많으면 훈련 시간이 매우 길어진다.\n",
    "#대부분의 CNN 아키텍처는 하나 이상의 Dense 레이어를 연결 시킨 후, 마지막 ouput 레이어를 연결한다.\n",
    "model_m.add(Dense(num_classes, activation='softmax'))\n",
    "#마지막 output 레이어 이므로 output은 카테고리의 수인 10개가 된다. softmax 활성함수는 ouput 클래스에 대한 확률 분포를 생성한다.\n",
    "#Sigmoid 함수를 generalization 해 값의 범위를 [0, 1]로 스케일한다. 따라서 각 10개 클래스에 대해 [0, 1] 값의 확률이 나오게 된다.\n",
    "# Inspect model's layers, output shapes, number of trainable parameters\n",
    "print(model_m.summary())\n",
    "#Malireddi's Architecture은 모바일 앱에 적합한 작은 모델이다. \n",
    "#Chollet’s Architecture보다 convolutional layer(Conv2D)를 하나 더 가지고 있지만, 훨씬 더 빠르게 실행된다.\n",
    "#Total params의 크기 차이가 그 이유이다. 94,602개로 Chollet의 1,199,882보다 훨씬 적다. \n",
    "#모델 크기의 차이는 정확히 4.8MB와 380KB이다.\n",
    "#세 개의 Conv2D 레이어가 있으며, 각각의 레이어 다음에는 MaxPooling2D 레이어로 너비와 높이를 반으로 줄인다.\n",
    "#MaxPooling을 사용해, 매개 변수의 수를 줄여 모델의 전체적인 크기와 학습 속도를 높일 수 있다.\n",
    "#CNN 구현이 이미 최적화되어 있어 Conv 레이어를 추가해 학습 시간을 늘리지 않아도 정확도를 크게 떨어뜨리지 않는다.\n",
    "#또, dense layer(FC)가 작으면 실행 속도가 빨라진다.\n",
    "\n",
    "#Convolutional neural network는 input을 image로 가정하고 뉴런을 width, height, depth의 세 가지 차원으로 배열한다.\n",
    "#CNN은 convolutional layers로 구성되며, 각 레이어는 훈련 이미지의 higher-level feature를 감지한다.\n",
    "#ex. 첫 레이어 층은 다양한 각도의 짧은 선 또는 곡선을 감지하는 필터를 조정한다. \n",
    "#  두 번째 레이어 층은 필터를 훈련시켜 이전 레이어 층에서 감지한 선의 중요한 조합을 탐지한다. \n",
    "#  최종 레이어의 필터는 이전 레이어를 기반으로 이미지를 분류한다.\n",
    "#각 convolutional layer는 input에 대해 1x1, 3x3, 5x5 등의 가중치를 가지고 있는 사각형 커널(필터)을 전달하여 가중치 합을 계산한다.\n",
    "#이것이 convolution process이다. 각 뉴런은 이전 계층의 1, 9 또는 25개의 뉴런에만 연결되므로 작은 input에 너무 의존되는 경향이 있다.\n",
    "#이로 인해 co-adapting이 되고, overfitting이 일어날 수 있다. 따라서 CNN은 이를 막기 위해 pooling과 dropout 레이어를 포함한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Chollet's Architecture](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py)\n",
    "\n",
    "Chollet's Architecture은 범용적인 모델이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_c = Sequential()\n",
    "model_c.add(Conv2D(32, (3, 3), input_shape=input_shape, activation='relu'))\n",
    "# Note: hwchong, elitedatascience use 32 for second Conv2D\n",
    "model_c.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_c.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#Malireddi 모델에 비해, 두 개의 Conv 레이어 층 이후에 MaxPooling한다.\n",
    "#대규모 네트워크에서는 Conv layer가 복잡한 feature를 탐지할 수 있게 하기 위해 이런 식으로 구현하는 것이 좋다.\n",
    "model_c.add(Dropout(0.25))\n",
    "model_c.add(Flatten())\n",
    "model_c.add(Dense(128, activation='relu'))\n",
    "model_c.add(Dropout(0.5))\n",
    "model_c.add(Dense(num_classes, activation='softmax'))\n",
    "# Inspect model's layers, output shapes, number of trainable parameters\n",
    "print(model_c.summary())\n",
    "#Chollet's Architecture은 범용적인 모델이다. \n",
    "#Malireddi's Architecture보다 convolutional layer(Conv2D)가 하나 더 적다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "### Define Callbacks List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='acc', patience=1)\n",
    "]\n",
    "#callbacks은 fit 함수의 optional argument 이다. \n",
    "#epoch은 데이터 세트의 모든 mini-batches를 완전히 실행하는 것을 의미한다.\n",
    "#ModelCheckpoint은 validation loss value를 모니터링 하고, loss가 가장 낮은 모델을 저장한다.\n",
    "#EarlyStopping은 training의 정확도를 모니터링 한다. 2 epoch 동안 정확도가 개선되지 않으면 training을 중지한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile & Fit Model\n",
    "\n",
    "- On a MacBook Pro, this step takes approximately 15 minutes. Reducing `batch_size` or increasing `epochs` will increase the run time.\n",
    "- You can run this cell more than once, to improve the model's accuracy.\n",
    "- To *manually* stop early, click the stop button in the toolbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 114s - loss: 0.5950 - acc: 0.8018 - val_loss: 0.1553 - val_acc: 0.9536\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 125s - loss: 0.1936 - acc: 0.9396 - val_loss: 0.0909 - val_acc: 0.9704\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 118s - loss: 0.1428 - acc: 0.9556 - val_loss: 0.0723 - val_acc: 0.9783\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 127s - loss: 0.1157 - acc: 0.9640 - val_loss: 0.0559 - val_acc: 0.9836\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 119s - loss: 0.0981 - acc: 0.9693 - val_loss: 0.0463 - val_acc: 0.9861\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 134s - loss: 0.0891 - acc: 0.9721 - val_loss: 0.0409 - val_acc: 0.9873\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 111s - loss: 0.0806 - acc: 0.9747 - val_loss: 0.0373 - val_acc: 0.9885\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 114s - loss: 0.0723 - acc: 0.9768 - val_loss: 0.0356 - val_acc: 0.9885\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 112s - loss: 0.0658 - acc: 0.9791 - val_loss: 0.0371 - val_acc: 0.9883\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 106s - loss: 0.0630 - acc: 0.9799 - val_loss: 0.0292 - val_acc: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f738ca12f10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPU 사용할 수 없으면, Malireddi의 모델로 training 하는 것을 추천한다.\n",
    "model_m.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "#손실함수, 최적화 모델을 지정한다.\n",
    "#loss : categorical crossentropy 는 CNN으로 계산된 확률 분포 및 레이블의 실제 분포 사이의 거리를 측정한다.\n",
    "#optimizer : 확률 gradient down 알고리즘이다.\n",
    "#metrics : 올바르게 분류된 이미지의 비율(accuracy)을 통계로 가져온다. 가장 일반적인 측정 항목이다.\n",
    "\n",
    "# Hyper-parameters\n",
    "batch_size = 200\n",
    "#mini-batch stochastic gradient fitting에 사용하는 데이터 항목 수 이다. 작을 수로 epoch이 길어진다.\n",
    "#값이 클수록 GPU 병렬 처리를 잘 활용하고 데이터 전송시간을 줄인다. 하지만 너무 크면, 메모리가 부족해 질 수 있다.\n",
    "epochs = 10\n",
    "#각 epoch마다 손실을 줄이고 정확도를 높여야 한다. 값이 클수록 더 정확한 모델을 만들지만, 훈련 시간이 오래 걸린다.\n",
    "#또, 지나치게 많은 epoch은 overfitting을 초래한다. \n",
    "\n",
    "# Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
    "model_m.fit(\n",
    "    x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "    callbacks=callbacks_list, validation_data=(x_val, y_val), verbose=1)\n",
    "#training 시작\n",
    "#callbacks으로 모든 epoch를 완료하기 전에 모델이 개선되지 않으면 콜백으로 중단할 수도 있다.\n",
    "#validation data를 10000개 설정했다. 이 인수를 전달하면, 훈련하는 동안 유효성 검사를 해 유효성 검사의 자체 손실 및 정확도를 모니터링할 수 있다.\n",
    "#  이 값이 학습으로 출력 된 값보다 나쁠 경우, 해당 모델이 오버피팅 된 것임을 알 수 있다.\n",
    "#Verbose 의 값은 각 각 0 = silent, 1 = progress bar, 2 = one line per epoch 를 나타낸다. 훈련 시 현재 상황을 출력 해 보여준다.\n",
    "\n",
    "#출력 결과, 각 epoch마다 loss가 감소하고 accuracy가 증가해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convert to Core ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : conv2d_1_input, <keras.engine.topology.InputLayer object at 0x7f737dbd2590>\n",
      "1 : conv2d_1, <keras.layers.convolutional.Conv2D object at 0x7f737dbd2550>\n",
      "2 : conv2d_1__activation__, <keras.layers.core.Activation object at 0x7f7364145510>\n",
      "3 : max_pooling2d_1, <keras.layers.pooling.MaxPooling2D object at 0x7f737dbd2910>\n",
      "4 : conv2d_2, <keras.layers.convolutional.Conv2D object at 0x7f737db61e90>\n",
      "5 : conv2d_2__activation__, <keras.layers.core.Activation object at 0x7f7364145710>\n",
      "6 : max_pooling2d_2, <keras.layers.pooling.MaxPooling2D object at 0x7f737db796d0>\n",
      "7 : conv2d_3, <keras.layers.convolutional.Conv2D object at 0x7f737db34dd0>\n",
      "8 : conv2d_3__activation__, <keras.layers.core.Activation object at 0x7f7364145990>\n",
      "9 : max_pooling2d_3, <keras.layers.pooling.MaxPooling2D object at 0x7f737db4a610>\n",
      "10 : flatten_1, <keras.layers.core.Flatten object at 0x7f737db0ad10>\n",
      "11 : dense_1, <keras.layers.core.Dense object at 0x7f73c0583710>\n",
      "12 : dense_1__activation__, <keras.layers.core.Activation object at 0x7f7364145f50>\n",
      "13 : dense_2, <keras.layers.core.Dense object at 0x7f737dac8b50>\n",
      "14 : dense_2__activation__, <keras.layers.core.Activation object at 0x7f7364145a10>\n"
     ]
    }
   ],
   "source": [
    "#가장 낮은 val_loss 값을 가진 모델이 가장 적합한 모델이다.\n",
    "\n",
    "output_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] #출력 레이블\n",
    "# For the first argument, use the filename of the newest .h5 file in the notebook folder.\n",
    "coreml_mnist = coremltools.converters.keras.convert(\n",
    "    'best_model.09-0.03.h5', input_names=['image'], output_names=['output'], \n",
    "    class_labels=output_labels, image_input_names='image')\n",
    "#image_input_names를 image로 설정해, Core ML이 input을 multi-array가 아닌 image으로 받아 들이도록 한다.\n",
    "#coremltools를 사용해 모델을 Core ML 모델로 convert한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Inspect Core ML model\n",
    "\n",
    "Check the input type is `imageType`, not multi array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input {\n",
      "  name: \"image\"\n",
      "  type {\n",
      "    imageType {\n",
      "      width: 28\n",
      "      height: 28\n",
      "      colorSpace: GRAYSCALE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "output {\n",
      "  name: \"output\"\n",
      "  type {\n",
      "    dictionaryType {\n",
      "      stringKeyType {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "output {\n",
      "  name: \"classLabel\"\n",
      "  type {\n",
      "    stringType {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "predictedFeatureName: \"classLabel\"\n",
      "predictedProbabilitiesName: \"output\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(coreml_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add Metadata for Xcode\n",
    "\n",
    "Substitute your own name and license info for the first two items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_mnist.author = 'raywenderlich.com'\n",
    "coreml_mnist.license = 'Razeware'\n",
    "coreml_mnist.short_description = 'Image based digit recognition (MNIST)'\n",
    "coreml_mnist.input_description['image'] = 'Digit image'\n",
    "coreml_mnist.output_description['output'] = 'Probability of each digit'\n",
    "coreml_mnist.output_description['classLabel'] = 'Labels of digits'\n",
    "#Xcode용 메타 데이터를 추가한다. 이 정보는 Xcode의 프로젝트 탐색기에서 모델을 선택한 경우 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Save the Core ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_mnist.save('MNISTClassifier.mlmodel') #mlmodel을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
